{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "House Price Prediction using PyTorch - Tabular Dataset.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mARNM_o-_AE3",
        "U1hV_ujsN7vb",
        "8hFuXvy_R3V9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mARNM_o-_AE3"
      },
      "source": [
        "#Prerequisite....\r\n",
        "\r\n",
        "01. Theoretical knowledge of Deep Learning\r\n",
        "02. ANN with Pytorch\r\n",
        "03. Feature Engineering (Categorical --  Embedding Layer, Continous Variables)\r\n",
        "04. Pythonic Class to create feed Forward NN's\r\n",
        "\r\n",
        "\r\n",
        "###Tabular Dataset --> Dataset Which has rows and columns format\r\n",
        "\r\n",
        "#### Handle Datas\r\n",
        "01. Categorical Features -- Embedding Layers(in Pytorch)\r\n",
        "02. Continuous Featues -- NA  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-Qyf_Cq3er1"
      },
      "source": [
        "from google.colab import files\r\n",
        "file = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNL5r1pK-Wh5"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiNjezMMAQGn"
      },
      "source": [
        "#Lets Take most important Columns based on previous experience and dropping all NAN values\r\n",
        "df=pd.read_csv('houseprice.csv',usecols=[\"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\r\n",
        "                                         \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"]).dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqj0APRrAhj8"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w0qUK4yAiX3"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyzD64HmAkSW"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFXp9hf3An7n"
      },
      "source": [
        "#Checking Uniques values available in each columns\r\n",
        "#BAsed on unique numbers we can able to say that least is the count == Categorical values \r\n",
        "for i in df.columns:\r\n",
        "  print(\"Column name {} and unique values are {}\".format(i,len(df[i].unique())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ8p8CtjCJYL"
      },
      "source": [
        "#Lets fix feature \"YearBuilt\" like difference between year built and todays date\r\n",
        "#It will help to see Age of Buildings\r\n",
        "import datetime\r\n",
        "datetime.datetime.now().year"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-epmA1yDIjb"
      },
      "source": [
        "df[\"Total Years\"] = datetime.datetime.now().year-df['YearBuilt']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbVFmeFkDTdZ"
      },
      "source": [
        "df.drop(\"YearBuilt\", axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcpY83fBDb2B"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6XhLStsDfbu"
      },
      "source": [
        "#Lets split the features based on categorical and continuous features\r\n",
        "#Creating Categorical feature\r\n",
        "cat_features = [\"MSSubClass\",\"MSZoning\",\"Street\",\"LotShape\"]\r\n",
        "out_features = \"SalesPrice\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgUvJWaCEgxv"
      },
      "source": [
        "df[\"MSSubClass\"].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naqEoErKESQQ"
      },
      "source": [
        "#Lets fix some indexes for all unique values with in the column\r\n",
        "#Out motive is to give unique label for all numbers available thats why we dint used OnehotEncoding\r\n",
        "#LabelEncoder will sort all numbers first and later it will assign labels(i.e INDEXES)\r\n",
        "#LabelEncoding will help in Embedding process(assiging vectors)\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "lbl_encoders = {}\r\n",
        "for features in cat_features:\r\n",
        "  lbl_encoders[features] = LabelEncoder()\r\n",
        "  df[features] = lbl_encoders[features].fit_transform(df[features])\r\n",
        "\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilgQSS2nIdtY"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjccvoYlFLer"
      },
      "source": [
        "# Stacking and Converting Into Tensors\r\n",
        "\r\n",
        "cat_features = np.stack([df[\"MSSubClass\"], df[\"MSZoning\"], df[\"Street\"], df[\"LotShape\"]],1)\r\n",
        "cat_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XjVwKdcIcSo"
      },
      "source": [
        "# Convert numpy to Tensors\r\n",
        "# IMPORTANT ---> Categorical featires never be converted in to float\r\n",
        "import torch\r\n",
        "cat_features = torch.tensor(cat_features, dtype = torch.int64)\r\n",
        "cat_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRkUu40CJCEr"
      },
      "source": [
        "#Lets take all Continuous variables\r\n",
        "cont_features = []\r\n",
        "for i in df.columns:\r\n",
        "  if i in [\"MSSubClass\",\"MSZoning\",\"Street\",\"LotShape\",\"SalePrice\"]:\r\n",
        "    pass\r\n",
        "  else:\r\n",
        "    cont_features.append(i)\r\n",
        "cont_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCaLm6L_K8Se"
      },
      "source": [
        "#Stacking Coninuous variable to a tensor\r\n",
        "cont_values = np.stack([df[i].values for i in cont_features], axis = 1)\r\n",
        "cont_values = torch.tensor(cont_values, dtype = torch.float)\r\n",
        "cont_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay6fmASrL0uW"
      },
      "source": [
        "cont_values.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U43USgOyMzjD"
      },
      "source": [
        "# Dependent Features\r\n",
        "y = torch.tensor(df[\"SalePrice\"].values, dtype=torch.float).reshape(-1,1) #using reshape will give you 2D tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep904yBXNHJG"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0-7J9rJNUDk"
      },
      "source": [
        "#Shape of cat, cont and y features\r\n",
        "cat_features.shape, cont_values.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1hV_ujsN7vb"
      },
      "source": [
        "# Embedding for Categorical Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlBoDKKWN6BT"
      },
      "source": [
        "len(df[\"MSSubClass\"].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKlwvjdBOmPw"
      },
      "source": [
        "#Counting unique values in each columns\r\n",
        "cat_dims = [len(df[col].unique()) for col in [\"MSSubClass\",\"MSZoning\",\"Street\",\"LotShape\"]]\r\n",
        "cat_dims #Input Dimension for NN layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMXCTr5FO7WW"
      },
      "source": [
        "# Output dimension should be set based on input dimension(min(50,feature dimension/2))-- AS PER STANDARD\r\n",
        "#Cant go beyond 50\r\n",
        "#Example for \"MSSubClass\" we have 1 uniques values So, min(50,15/2(i.e 7.5)) --> 7\r\n",
        "#So, 7 is the output of emebedding layer\r\n",
        "embedding_dim = [(x, min(50, (x+1)//2)) for x in cat_dims] #---> // will give you INT values i.e 17 //2 == 8\r\n",
        "#We are taking x+1 instaed of just x just to get the higher number ##--> (15+1)//2 = 8 and 15//2 = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRTu9Y4kQYfx"
      },
      "source": [
        "embedding_dim\r\n",
        "#for \"MSSubClass\" my input dimension is 15 and outpur dimension is 8\r\n",
        "#for \"MSZoning\" my input dimension is 5 and outpur dimension is 3\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hFuXvy_R3V9"
      },
      "source": [
        "#*Data Pre Processing steps Completed..........................*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puXyZ42gQ8wD"
      },
      "source": [
        "# Creating Emebdding Layer and NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zdA2uW8QaRQ"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "embed_representation = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\r\n",
        "embed_representation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVNavqI2SUGm"
      },
      "source": [
        "cat_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1uVtVbcTQaI"
      },
      "source": [
        "#just for example...\r\n",
        "cat_featuresz = cat_features[:4]\r\n",
        "cat_featuresz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUKkXjP6TWU7"
      },
      "source": [
        "#Lets Convert into vectors with the help of embed_representation\r\n",
        "\r\n",
        "pd.set_option('display.max_rows', 500)\r\n",
        "embedding_val = []\r\n",
        "for i, e in enumerate(embed_representation):\r\n",
        "  embedding_val.append(e(cat_features[:,i]))\r\n",
        "\r\n",
        "embedding_val\r\n",
        "\r\n",
        "\r\n",
        "#So the first value 5 in cat_featuresz will be represented as 8 values in first row of embedding_val\r\n",
        "#value 0 in cat_featuresz will be represented as 8 values in second row of embedding_val\r\n",
        "# ..... for all \"MSSubClass\" \r\n",
        "#Next we will get only 3 values for second column...\r\n",
        "#SO On,,,,,,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEPZjlxMUPei"
      },
      "source": [
        "# embedding_val not stcked properly so,\r\n",
        "\r\n",
        "z = torch.cat(embedding_val,1) #cat--concat in torch\r\n",
        "z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvLp-lpJV_Lb"
      },
      "source": [
        "## Implement Dropout to overcome overfitting\r\n",
        "dropout = nn.Dropout(.4) #.4 = 40%\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsllCFFZW4BB"
      },
      "source": [
        "final_embed = dropout(z)\r\n",
        "final_embed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSi2stLbW9Re"
      },
      "source": [
        "##### Create a Feed Forward Neural Network\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "class FeedForwardNN(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, embedding_dim, n_cont, out_sz, layers, p=0.5): #out_sz -output layer | p -- droput ratio\r\n",
        "        super().__init__() #inheriting all the paremeters from nn.Module\r\n",
        "        self.embeds = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim]) #Embedding layer\r\n",
        "        self.emb_drop = nn.Dropout(p)\r\n",
        "        self.bn_cont = nn.BatchNorm1d(n_cont) #Batch Norm w.r.t no of continuous variables\r\n",
        "        \r\n",
        "        layerlist = []\r\n",
        "        n_emb = sum((out for inp,out in embedding_dim)) #Total dimension for embedding layers\r\n",
        "        n_in = n_emb + n_cont #(embedding feature(cat) + continuous features)\r\n",
        "        \r\n",
        "        #Creating layers and nuerons\r\n",
        "        for i in layers:\r\n",
        "            layerlist.append(nn.Linear(n_in,i)) \r\n",
        "            layerlist.append(nn.ReLU(inplace=True))\r\n",
        "            layerlist.append(nn.BatchNorm1d(i))\r\n",
        "            layerlist.append(nn.Dropout(p))\r\n",
        "            n_in = i\r\n",
        "        layerlist.append(nn.Linear(layers[-1],out_sz))\r\n",
        "            \r\n",
        "        self.layers = nn.Sequential(*layerlist)\r\n",
        "    \r\n",
        "    def forward(self, x_cat, x_cont):\r\n",
        "        embeddings = []\r\n",
        "        for i,e in enumerate(self.embeds):\r\n",
        "            embeddings.append(e(x_cat[:,i]))\r\n",
        "        x = torch.cat(embeddings, 1)\r\n",
        "        x = self.emb_drop(x)\r\n",
        "        \r\n",
        "        x_cont = self.bn_cont(x_cont)\r\n",
        "        x = torch.cat([x, x_cont], 1)\r\n",
        "        x = self.layers(x)\r\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PzbBdUkcbAe"
      },
      "source": [
        "len(cont_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g308QNTcncC"
      },
      "source": [
        "torch.manual_seed(100) #If u use 100 then the same parameters will be assigned over every itiration\r\n",
        "model = FeedForwardNN(embedding_dim,len(cont_features),1,[100,50],p=0.4)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-xiAtRzdI9I"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGFAC4ZidnxF"
      },
      "source": [
        "#Define Loss And Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx1B5-YyfxkI"
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K23kRNwIdfdX"
      },
      "source": [
        "loss_function = nn.MSELoss() #Later convert this in to RMSE\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01) #model.parameters --> these are the generator and it will throw output one by one | to know this u can use \"model.parameters()\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yI8_a2ueFWh"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vm5JgCVeHd4"
      },
      "source": [
        "print(cont_values)\r\n",
        "print(cont_values.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0PDRwq1f3rd"
      },
      "source": [
        "#Train Test Split\r\n",
        "batch_size=1200\r\n",
        "test_size=int(batch_size*0.15) #15% of whole data as test dataset i.e 180\r\n",
        "train_categorical=cat_features[:batch_size-test_size] #---> [starting to (1200-180)]\r\n",
        "test_categorical=cat_features[batch_size-test_size:batch_size] #---> [(1200-180) to 1200]\r\n",
        "train_cont=cont_values[:batch_size-test_size]\r\n",
        "test_cont=cont_values[batch_size-test_size:batch_size]\r\n",
        "y_train=y[:batch_size-test_size]\r\n",
        "y_test=y[batch_size-test_size:batch_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpPxUf5tgGSA"
      },
      "source": [
        "len(train_categorical),len(test_categorical),len(train_cont),len(test_cont),len(y_train),len(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFAbwBYcgj2S"
      },
      "source": [
        "\r\n",
        "epochs=500\r\n",
        "final_losses=[]\r\n",
        "#Run the number of epochs\r\n",
        "for i in range(epochs):\r\n",
        "    i=i+1\r\n",
        "    y_pred=model(train_categorical,train_cont) \r\n",
        "    loss=torch.sqrt(loss_function(y_pred,y_train)) ### RMSE\r\n",
        "    final_losses.append(loss)\r\n",
        "    if i%10==1:\r\n",
        "        print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\r\n",
        "    optimizer.zero_grad()\r\n",
        "    loss.backward() #backpropogation\r\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AasbclNGhxXC"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "plt.plot(range(epochs), final_losses)\r\n",
        "plt.ylabel('RMSE Loss')\r\n",
        "plt.xlabel('epoch');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC1ey3MllOIN"
      },
      "source": [
        "#### Validate the Test Data\r\n",
        "y_pred=\"\"\r\n",
        "with torch.no_grad():\r\n",
        "    y_pred=model(test_categorical,test_cont)\r\n",
        "    loss=torch.sqrt(loss_function(y_pred,y_test))\r\n",
        "print('RMSE: {}'.format(loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYUvy2g3lOfY"
      },
      "source": [
        "data_verify=pd.DataFrame(y_test.tolist(),columns=[\"Test\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz2fcc-flT7g"
      },
      "source": [
        "data_predicted=pd.DataFrame(y_pred.tolist(),columns=[\"Prediction\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms4WN4z9lWSB"
      },
      "source": [
        "data_predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALwugGP9lYPn"
      },
      "source": [
        "final_output=pd.concat([data_verify,data_predicted],axis=1)\r\n",
        "final_output['Difference']=final_output['Test']-final_output['Prediction']\r\n",
        "final_output.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2yHBzFollYa"
      },
      "source": [
        "#### Saving The Model\r\n",
        "#### Save the model\r\n",
        "# Extension for saving pytorch model is \".pt\"\r\n",
        "torch.save(model,'HousePrice.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUO1VPfXlwNU"
      },
      "source": [
        "torch.save(model.state_dict(),'HouseWeights.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWw4maill_jP"
      },
      "source": [
        "### Loading the saved Model\r\n",
        "embs_size=[(15, 8), (5, 3), (2, 1), (4, 2)]\r\n",
        "model1=FeedForwardNN(embs_size,5,1,[100,50],p=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON-LmMghmJP9"
      },
      "source": [
        "model1.load_state_dict(torch.load('HouseWeights.pt')) #Saving weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgqF0tGrmL83"
      },
      "source": [
        "model1.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqlDAzctmV0M"
      },
      "source": [
        "\r\n",
        "# ..............................THANK YOU............................\r\n",
        "---\r\n",
        "\r\n"
      ]
    }
  ]
}