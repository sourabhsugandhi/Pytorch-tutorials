{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN Using PyTorch.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4totM-QASzr7"
      },
      "source": [
        "from google.colab import files\r\n",
        "file = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCoyFotXZEbz"
      },
      "source": [
        "import pandas as pd\r\n",
        "df = pd.read_csv('Pima_Diabetes_Dataset.csv')\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gHZQzV8cN1r"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQaBZ85HcYLN"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR098N8hc40M"
      },
      "source": [
        "#As seaborn can not understand our dependent feature values which are numirical, we are converting that in to categorical\r\n",
        "#YOU CAN SKIP THIS PROCESS IF YOU DONT WANT TO SEE RELATION BETWEEN DEPEDENT(X) and INDEPENDENT(Y) FEATURE VALUES <--------------------------------\r\n",
        "df['Outcome'] = np.where(df[\"Outcome\"] == 1, \"Diabetic\", \"No Diabatic\")\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lax11f_wdoPl"
      },
      "source": [
        "sns.pairplot(df, hue=\"Outcome\") #hue --> holds dependent feature values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAbKeQuId0tW"
      },
      "source": [
        "#As we cant work on CAT values of  \"Outcome\" we are reading dataset again\r\n",
        "df = pd.read_csv('Pima_Diabetes_Dataset.csv')\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrOBiOkffY1m"
      },
      "source": [
        "X = df.drop(\"Outcome\", axis = 1).values\r\n",
        "y = df[\"Outcome\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j42IuN-leuHg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.8, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESc93m9pf3uq"
      },
      "source": [
        "### Libraries from Pytorch\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn #Helps to create models\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYtlQHFDfmOz"
      },
      "source": [
        "####### CREATING TENSORS\r\n",
        "\r\n",
        "###It is compulsory to have all dependent values to be in FLoat while creating Tensors\r\n",
        "X_train = torch.FloatTensor(X_train)\r\n",
        "X_test = torch.FloatTensor(X_test)\r\n",
        "y_train = torch.LongTensor(y_train) #We dont want depedent values to be in Float dtype\r\n",
        "y_test = torch.LongTensor(y_test)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVcZcJr7h6w9"
      },
      "source": [
        "### CREATING MODEL USING PYTORCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnConQGdibUK"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpXjOsGah84Y"
      },
      "source": [
        "# Before creating a model we need to define a class\r\n",
        "# input_feature --> input values(depedent(8 out of 9 available in dataset))\r\n",
        "# hidden1 and hidden2 --> hidden layer 1 and 2 with no of nuerons\r\n",
        "# out_features --> no of output feature values(in this case 1 and 0)\r\n",
        "\r\n",
        "class ANN_Model(nn.Module):\r\n",
        "  def __init__(self,input_features = 8, hidden1 = 20, hidden2 = 20, out_features=2):\r\n",
        "    #IN-herit the parent class nn.model\r\n",
        "    super().__init__()\r\n",
        "    #create fully connected layer\r\n",
        "    self.f_connected1 = nn.Linear(input_features, hidden1) #Connecting input layer to hidden l;ayer.. from 8 to 20\r\n",
        "    self.f_connected2 = nn.Linear(hidden1, hidden2) #Connecting hidden1 layer to hidden2\r\n",
        "    self.out = nn.Linear(hidden2,out_features) #Output layer\r\n",
        "\r\n",
        "  def forward(self,x): #x --> variable to track gradient descent and all forward prop things\r\n",
        "    x = F.relu(self.f_connected1(x)) #we added \"x\" here to track the progress in this layer\r\n",
        "    x = F.relu(self.f_connected2(x))\r\n",
        "    x = self.out(x)\r\n",
        "    return x\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMVDRYEIgrtn"
      },
      "source": [
        "## Instantiate ANN_Model\r\n",
        "## Before doing anything we need to set a seed so that initial weights gets applied\r\n",
        "##Lets take a manual seed value\r\n",
        "\r\n",
        "torch.manual_seed(20) #If u use 20 then the same parameters will be assigned over every itiration\r\n",
        "model = ANN_Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQu4vE8zlubZ"
      },
      "source": [
        "# To see whole information\r\n",
        "\r\n",
        "model.parameters #these are the generator and it will throw output one by one | to know this u can use \"model.parameters()\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPli0SnKmBdq"
      },
      "source": [
        "## Backward propogation --> define the loss_function | define the optimizer\r\n",
        "# loss_function --> will give difference in predicted and actual values\r\n",
        "# Optimizer --> to reduce the difference\r\n",
        "# lr --> learning rate --> it should not be very very small or very very high else we never be able to find global minima\r\n",
        "\r\n",
        "loss_function = nn.CrossEntropyLoss() #You can use this when you have multiclass classification\r\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPLh79MBnbEg"
      },
      "source": [
        "epochs = 20\r\n",
        "final_losses = []\r\n",
        "\r\n",
        "#Run the number of epochs\r\n",
        "\r\n",
        "for i in range(epochs):\r\n",
        "  i = i+1\r\n",
        "  y_pred = model.forward(X_train) #initializing forward propogation\r\n",
        "  loss = loss_function(y_pred, y_train) #calculating losses\r\n",
        "  final_losses.append(loss)\r\n",
        "  # On every tenth epoch print following\r\n",
        "  if i%10 == 1:\r\n",
        "    print(\"Epoch number is :{} and the loss is:{}\".format(i, loss.item()))\r\n",
        "  optimizer.zero_grad() #Creates the gradients of all optimized class\r\n",
        "  loss.backward()\r\n",
        "  optimizer.step() #performs a single optimization step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42vh0WIKo9xM"
      },
      "source": [
        "#Plot the loss function\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKLmU7mfpdoq"
      },
      "source": [
        "#Plot a graph to see loss over every epochs\r\n",
        "plt.plot(range(epochs), final_losses)\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.xlabel(\"Epoch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHHMrkRvpxQ6"
      },
      "source": [
        "## Prediction in X_test data\r\n",
        "prediction = []\r\n",
        "with torch.no_grad(): #While evaluating the results we dont want to see gardients\r\n",
        "  for i, data in enumerate(X_test): #enumerate will help to iterate all x_test data\r\n",
        "    y_pred = model(data) #Apply model\r\n",
        "    prediction.append(y_pred.argmax().item()) #argmax --> can help to which index max it is\r\n",
        "    print(y_pred.argmax().item()) #argmax --> can help to which index max it is"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8WaN8FyqVnw"
      },
      "source": [
        "#Lets compare prediction with y_test data\r\n",
        "import sklearn\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "cm = confusion_matrix(y_test, prediction)\r\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT2IqW4oxy5z"
      },
      "source": [
        "##### 320 and 84 --> right results\r\n",
        "##### 135 and 76 --> wrong results\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFydwxVpwfWM"
      },
      "source": [
        "#Design confussion matrix\r\n",
        "\r\n",
        "plt.figure(figsize = (10,6))\r\n",
        "sns.heatmap(cm,annot  = True)\r\n",
        "plt.xlabel(\"Actual Values\")\r\n",
        "plt.ylabel(\"Predicted Values\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiZwt3bJyXPt"
      },
      "source": [
        "#To find accuracy\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "score = accuracy_score(y_test,prediction)\r\n",
        "score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sljenTk6yyhl"
      },
      "source": [
        "## SAVE THE MODEL\r\n",
        "\r\n",
        "torch.save(model, \"diabetes.pt\") #Extension for saving pytorch model is \".pt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-L-wBkDzMp5"
      },
      "source": [
        "## Prediction of new data point\r\n",
        "list(df.iloc[0,:-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7NYRfk_zpBY"
      },
      "source": [
        "#Copy the above to create a new data\r\n",
        "\r\n",
        "lst1 = [6.0, 130.0, 72.0, 40.0, 0.0, 25.6, 0.627, 45.0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCSGTkl2z4a3"
      },
      "source": [
        "new_data = torch.tensor(lst1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H_q3SkB0AKr"
      },
      "source": [
        "# Predict new data using PyTorch\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "  print(model(new_data))\r\n",
        "  print(model(new_data).argmax().item())\r\n",
        "\r\n",
        "# for the given attributes if we get 0 --> no diabetes and for 1 --> Diabetes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDohrF6s0q4S"
      },
      "source": [
        "\r\n",
        "THANK YOU\r\n",
        "---\r\n",
        "\r\n"
      ]
    }
  ]
}